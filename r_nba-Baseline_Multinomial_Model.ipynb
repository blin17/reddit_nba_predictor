{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from scipy.optimize import minimize\n",
    "import sklearn.preprocessing as preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_csv_files(path):\n",
    "    pattern = r'^.*\\.csv$'\n",
    "    return [f for f in os.listdir(path) if bool(re.match(pattern,f))]\n",
    "    \n",
    "path = 'data/backlog/'\n",
    "csv_files = return_csv_files(path)\n",
    "df = pd.DataFrame()\n",
    "for csv in csv_files:\n",
    "    csv_df = pd.read_csv(path + csv)\n",
    "    df = pd.concat([df,csv_df])\n",
    "df['created'] = pd.to_datetime(df.created, unit = 's')\n",
    "df.index = range(0,len(df))\n",
    "# 18,001 total examples with no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Randomly shuffle the dataframe and generates a training, cross-validation, and test set\n",
    "'''\n",
    "random_df = df.reindex(np.random.permutation(df.index))\n",
    "training_df = random_df.iloc[0:12000]\n",
    "cross_validation_df = random_df.iloc[12000:15000]\n",
    "test_df = random_df.iloc[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return np.power(1 + np.exp(-z), -1)\n",
    "\n",
    "def logistic_cost_regularized(theta, Xdata, Ydata, lam=1):\n",
    "    # NB Xdata must be a numpy array\n",
    "\n",
    "    m = float(len(Xdata))\n",
    "    \n",
    "    J = (\n",
    "        - 1/m * (np.log(sigmoid(Xdata.dot(theta))).dot(Ydata) + \n",
    "        np.log(1-sigmoid(Xdata.dot(theta))).dot(1-Ydata) ) + \n",
    "        lam/(2*m) * np.sum(theta[1:] ** 2) \n",
    "        )\n",
    "    if np.isnan(J):\n",
    "        return(np.inf)\n",
    "    return(J)\n",
    "\n",
    "def logistic_grad_regularized(theta, Xdata, Ydata, lam=1):\n",
    "    # NB Xdata must be a numpy array\n",
    "    m = float(len(Xdata))\n",
    "    \n",
    "    grad = theta.copy() * lam\n",
    "    grad[0] = 0\n",
    "    grad += Xdata.T.dot(sigmoid(Xdata.dot(theta))-Ydata)\n",
    "    grad *= 1/m \n",
    "    \n",
    "    return grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def softmax(X_data, Y_data, num_Y):\n",
    "    poly = preprocessing.PolynomialFeatures(2)\n",
    "    X_Transformed = poly.fit_transform(X_data.values.reshape(len(X_data),1))\n",
    "    scaler = preprocessing.StandardScaler().fit(X_Transformed)\n",
    "    X_Transformed = scaler.transform(X_Transformed) \n",
    "    softmax_weights = []\n",
    "    for i in range(len(num_Y)+1):\n",
    "        Y = Y_data.apply(lambda d: 1 if d == i else 0).values\n",
    "        theta = np.zeros((X_Transformed.shape[1],))\n",
    "        res = minimize(logistic_cost_regularized, theta, args=(X_Transformed,Y, 1)\n",
    "                       , method = 'Nelder-Mead', jac=logistic_grad_regularized, options={'maxiter':400})\n",
    "        softmax_weights.append(res.x)\n",
    "    return softmax_weights\n",
    "\n",
    "def predict_values(X_Data, thetas, weights):\n",
    "    poly = preprocessing.PolynomialFeatures(2)\n",
    "    X_Transformed = poly.fit_transform(X_Data.values.reshape(len(X_Data),1))\n",
    "    scaler = preprocessing.StandardScaler().fit(X_Transformed)\n",
    "    X_Transformed = scaler.transform(X_Transformed) \n",
    "    hyp = []\n",
    "    for theta in thetas:\n",
    "        hyp.append(X_Transformed.dot(theta))\n",
    "    probs = []\n",
    "    for h in np.array(hyp).T:\n",
    "        num = np.exp(h)\n",
    "        den = np.exp(h).sum()\n",
    "        num *= weights\n",
    "        probs.append(num/den)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(column):\n",
    "    mean = np.mean(column)\n",
    "    sd = np.std(column)\n",
    "    return column.apply(lambda d: (d-mean)/sd)\n",
    "\n",
    "def bucketize(separators, num):\n",
    "    for s in range(len(separators)):\n",
    "        if num < separators[s]:\n",
    "            return s\n",
    "    return len(separators)\n",
    "\n",
    "def accuracy(predicted_Y, Y):\n",
    "    return sum(predicted_Y == Y)/float(len(predicted_Y))\n",
    "\n",
    "def accuracy_on_set(df, theta, weights, cutoffs): \n",
    "    data = df[['num_comments', 'score']]\n",
    "    X_data = data.num_comments\n",
    "    Y_data = data.score.apply(lambda d: bucketize(cutoffs,d))\n",
    "    prob_Y = pd.DataFrame(predict_values(X_data, thetas, weights))\n",
    "    predicted_Y = prob_Y.apply(lambda d: d.argmax(), axis=1).rename('predicted')\n",
    "    prob_Y.index = Y_data.index\n",
    "    predicted_Y.index = Y_data.index\n",
    "    #comparison = pd.concat([prob_Y, predicted_Y, Y, training_df.num_comments], axis=1)\n",
    "    return accuracy(predicted_Y,Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianlin/anaconda/lib/python2.7/site-packages/scipy/optimize/_minimize.py:381: RuntimeWarning: Method Nelder-Mead does not use gradient information (jac).\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Groups the labels into 4 karma categories: low, medium-low, medium-high, high\n",
    "    cutoffs(var) is the karma score cutoffs for the groups\n",
    "    softmax(func) runs the data through a softmax regression model and returns the training weights for each group\n",
    "    weights(var) are the weights that are apply on the probabilities to return an accurate cutoff\n",
    "    accuracy_on_set(func) predicts the Y from the model and compares it to the actual Y and returns a prediction\n",
    "'''\n",
    "\n",
    "cutoffs = [50, 150, 350]\n",
    "weights = np.array([.50,1.1,1.1,1.])\n",
    "\n",
    "data = training_df[['num_comments', 'score']]\n",
    "X_data = data.num_comments\n",
    "Y_data = data.score.apply(lambda d: bucketize(cutoffs,d))\n",
    "thetas = softmax(X_data, Y_data, cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.634833333333\n",
      "Validation Accuracy: 0.625\n",
      "Test Accuracy: 0.676441186271\n"
     ]
    }
   ],
   "source": [
    "print 'Training Accuracy:', accuracy_on_set(training_df, thetas, weights, cutoffs)\n",
    "print 'Validation Accuracy:', accuracy_on_set(cross_validation_df, thetas, weights, cutoffs)\n",
    "print 'Test Accuracy:', accuracy_on_set(test_df, thetas, weights, cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7320\n",
       "3    2014\n",
       "1    1846\n",
       "2     820\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = training_df[['num_comments', 'score']]\n",
    "X_data = data.num_comments\n",
    "Y_data = data.score.apply(lambda d: bucketize(cutoffs,d))\n",
    "prob_Y = pd.DataFrame(predict_values(X_data, thetas, weights))\n",
    "predicted_Y = prob_Y.apply(lambda d: d.argmax(), axis=1).rename('predicted')\n",
    "predicted_Y.value_counts()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
