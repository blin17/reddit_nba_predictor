{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Analysis of /r/nba Posts\n",
    "@author: Brian Lin\n",
    "'''\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_csv_files(path):\n",
    "    pattern = r'^.*\\.csv$'\n",
    "    return [f for f in os.listdir(path) if bool(re.match(pattern,f))]\n",
    "    \n",
    "path = 'data/backlog/'\n",
    "csv_files = return_csv_files(path)\n",
    "df = pd.DataFrame()\n",
    "for csv in csv_files:\n",
    "    csv_df = pd.read_csv(path + csv)\n",
    "    df = pd.concat([df,csv_df])\n",
    "df['created_timestamp'] = pd.to_datetime(df.created, unit = 's')\n",
    "df.index = range(0,len(df))\n",
    "# 18,001 total examples with no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Randomly shuffle the dataframe and generates a training, cross-validation, and test set\n",
    "'''\n",
    "random_df = df.reindex(np.random.permutation(df.index))\n",
    "training_df = random_df.iloc[0:12000]\n",
    "cross_validation_df = random_df.iloc[12000:15000]\n",
    "test_df = random_df.iloc[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def front_page(score,n=150):\n",
    "    if score >= n:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "training_Y = training_df.score.apply(front_page)\n",
    "cross_validation_Y = cross_validation_df.score.apply(front_page)\n",
    "test_Y = test_df.score.apply(front_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_words = pd.read_csv('common_words.txt', header = None)[0].values\n",
    "\n",
    "def remove_common_words(title, common_words):\n",
    "    tw = map(lambda d: d.strip(\".,:()[]!?\\\"\").lower(),title.split())\n",
    "    return [w for w in tw if w not in common_words]\n",
    "\n",
    "def generate_words_and_scores(titles, score, common_words):\n",
    "    title_words = []\n",
    "    score_words = []\n",
    "    for index in range(len(titles)):\n",
    "        title_word_list = remove_common_words(titles.iloc[index], common_words)\n",
    "        title_words.extend(title_word_list)\n",
    "        score_words.extend([scores.iloc[index]] * len(title_word_list))\n",
    "    title_words_s = pd.Series(title_words)\n",
    "    words_scores_df = pd.concat([title_words_s, pd.Series(score_words)], axis = 1)\n",
    "    words_scores_df.columns = ['word', 'score']\n",
    "    return words_scores_df\n",
    "\n",
    "titles = training_df.title\n",
    "scores = training_df.score\n",
    "word_df = generate_words_and_scores(titles,scores, common_words)\n",
    "word_df_agg = word_df.groupby('word').agg({'score':['mean','std','median','count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_sorted_median = word_df_agg[word_df_agg[('score','count')] > 10].sort_values(by=[('score','median')], ascending=False)\n",
    "top200 = np.array(words_sorted_median[:200].index)\n",
    "bottom200 = np.array(words_sorted_median[-200:].index)\n",
    "top_bottom200 = np.array(pd.concat([words_sorted_median[:200],words_sorted_median[-200:]]).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generates the feature word vectors\n",
    "def create_feature_row(title, word_vec):\n",
    "    feature_row = np.zeros((len(word_vec),))\n",
    "    for word in title:\n",
    "        if word in word_vec:\n",
    "            word_index = np.where(word_vec==word)[0][0]\n",
    "            feature_row[word_index] = 1\n",
    "    return feature_row\n",
    "\n",
    "def generate_feature_vector(title_s, top_words, common_words):\n",
    "    l = []\n",
    "    for title in title_s:\n",
    "        title_r = remove_common_words(title, common_words)\n",
    "        l.append(create_feature_row(title_r, top_words))\n",
    "    return l\n",
    "\n",
    "def sanitize_titles(title_s):\n",
    "    l = []\n",
    "    for title in title_s:\n",
    "        title_r = remove_common_words(title, common_words)\n",
    "        l.append(title_r)\n",
    "    return l\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_score(predicted_p, Y,threshold=0.5):\n",
    "    def greater_than_one_half(x):\n",
    "        if x > threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    predicted_Y = np.array([greater_than_one_half(x) for x in predicted_p])\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    true_neg = 0\n",
    "    false_neg = 0\n",
    "    for i in range(len(predicted_Y)):\n",
    "        if predicted_Y[i] == 1 and Y[i] == 1:\n",
    "            true_pos +=1\n",
    "        elif predicted_Y[i] == 1 and Y[i] == 0:\n",
    "            false_pos +=1\n",
    "        elif predicted_Y[i] == 0 and Y[i] == 1:\n",
    "            true_neg +=1\n",
    "        elif predicted_Y[i] == 0 and Y[i] == 0:\n",
    "            false_neg +=1\n",
    "    \n",
    "    wrong = float(np.sum(np.abs(predicted_Y - Y)))\n",
    "    total = float(len(predicted_Y))\n",
    "    ans = dict()\n",
    "    ans['accuracy'] =  1-(wrong/total)\n",
    "    ans['true_pos'] = true_pos\n",
    "    ans['true_neg'] = true_neg\n",
    "    ans['false_pos'] = false_pos\n",
    "    ans['false_neg'] = false_neg\n",
    "    if true_pos == 0 and false_pos == 0:\n",
    "        ans['recall'] = float(true_pos) / float((true_pos + true_neg))\n",
    "    elif true_pos == 0 and true_neg == 0:\n",
    "        ans['precision'] = float(true_pos) / float((true_pos + false_pos))\n",
    "    else:\n",
    "        ans['precision'] = float(true_pos) / float((true_pos + false_pos))\n",
    "        ans['recall'] = float(true_pos) / float((true_pos + true_neg))\n",
    "        ans['f1_score'] = 2 * ans['precision'] * ans['recall'] / (ans['precision'] + ans['recall'] )\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_bayes_prob(words, X, Y):\n",
    "    pxy1 = {}\n",
    "    pxy0 = {}\n",
    "    for index in range(len(words)):\n",
    "        word = words[index]\n",
    "        pxy1[word] = float(sum((X.iloc[:,index] == 1) & (Y == 1)) +1) / float(sum(Y.values == 1) +2)\n",
    "        pxy0[word] = float(sum((X.iloc[:,index] == 1) & (Y == 0)) +1) / float(sum(Y.values == 0) +2)\n",
    "    return pxy1, pxy0\n",
    "\n",
    "def calculate_prob(sanitized_title_list,debug=False):\n",
    "    global bayes_pxy1,bayes_pxy0, py1, py0,pno1, pno0\n",
    "    pyx1 = 1.0\n",
    "    pyx0 = 1.0\n",
    "    for word in sanitized_title_list:\n",
    "        if word in bayes_pxy1:\n",
    "            pyx1 *= bayes_pxy1[word]\n",
    "            pyx0 *= bayes_pxy0[word]\n",
    "            if debug:\n",
    "                print 'yes'\n",
    "        else:\n",
    "            pyx1 *= pno1\n",
    "            pyx0 *= pno0\n",
    "            if debug:\n",
    "                print 'no'    \n",
    "        if debug:\n",
    "            print word, pyx1, pyx0\n",
    "    return pyx1*py1, pyx0*py0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vector = np.array(word_df_agg.index)\n",
    "#word_vector = top_bottom200\n",
    "title_features_bayes_df = pd.DataFrame(generate_feature_vector(titles,word_vector,common_words), index = training_df.index)\n",
    "sum(title_features_bayes_df.sum(axis =1) == 0)\n",
    "bayes_pxy1,bayes_pxy0 = generate_bayes_prob(word_vector, title_features_bayes_df, training_Y)\n",
    "Y = training_Y\n",
    "py1 = float(sum(Y.values == 1)) / len(Y)\n",
    "py0 = float(sum(Y.values == 0)) / len(Y)\n",
    "pno1 = 1/float(sum(Y.values == 1))\n",
    "pno0 = 1/float(sum(Y.values == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7124"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanitized_titles = sanitize_titles(training_df.title)\n",
    "class_probs = []\n",
    "for i in range(len(sanitized_titles)):\n",
    "    title = sanitized_titles[i]\n",
    "    class_probs.append(calculate_prob(title))\n",
    "probs = pd.DataFrame(class_probs)\n",
    "sum(probs[0] > probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14939</th>\n",
       "      <td>Faking fivethrityeight.com's CARMELO -- 2016-1...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.459184e-22</td>\n",
       "      <td>8.986296e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15268</th>\n",
       "      <td>Huertas comes up with the sneakiest steal I've...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.264399e-23</td>\n",
       "      <td>2.395620e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15990</th>\n",
       "      <td>Without contract, Smith to skip Cavs minicamp</td>\n",
       "      <td>238.0</td>\n",
       "      <td>8.490667e-13</td>\n",
       "      <td>1.745827e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3027</th>\n",
       "      <td>[Jon Wilner] Warriors GM Myers says no offseas...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.526078e-24</td>\n",
       "      <td>5.287127e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>Lebron James Gets in Stephen Curry's Face - Ga...</td>\n",
       "      <td>168.0</td>\n",
       "      <td>1.112694e-15</td>\n",
       "      <td>6.451405e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  score             0  \\\n",
       "14939  Faking fivethrityeight.com's CARMELO -- 2016-1...   26.0  1.459184e-22   \n",
       "15268  Huertas comes up with the sneakiest steal I've...   23.0  7.264399e-23   \n",
       "15990      Without contract, Smith to skip Cavs minicamp  238.0  8.490667e-13   \n",
       "3027   [Jon Wilner] Warriors GM Myers says no offseas...   20.0  6.526078e-24   \n",
       "1111   Lebron James Gets in Stephen Curry's Face - Ga...  168.0  1.112694e-15   \n",
       "\n",
       "                  1  \n",
       "14939  8.986296e-23  \n",
       "15268  2.395620e-23  \n",
       "15990  1.745827e-13  \n",
       "3027   5.287127e-24  \n",
       "1111   6.451405e-17  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.index = training_df.index\n",
    "pd.concat([training_df[probs[0] > probs[1]][['title','score']], probs], axis=1, join= 'inner').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'hour'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-881d65f40951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#2016-06-08 06:26:36\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtraining_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/brianlin/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2220\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:62658)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-881d65f40951>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#2016-06-08 06:26:36\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtraining_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'hour'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "#2016-06-08 06:26:36\n",
    "training_df[(Y.values == 0)].created.apply(lambda d: d.hour).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_df[(predicted_Y3 == 1) & (Y.values == 1)][['title','score','domain','created']].domain.value_counts()[:15].plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_predicted3 = probs.apply(lambda d: 1 if d[0] > d[1] else 0, axis = 1)\n",
    "predicted_Y3 = np.array(Y_predicted3)\n",
    "p_score = prediction_score(predicted_Y3, Y.values)\n",
    "p_score"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
