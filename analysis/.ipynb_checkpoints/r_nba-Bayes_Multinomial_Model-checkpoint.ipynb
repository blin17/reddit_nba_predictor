{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Multinomial Naive Bayes on /r/nba Posts\n",
    "@author: Brian Lin\n",
    "'''\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('../lib/')\n",
    "import Bayes_Helper as bayes\n",
    "import Multinomial_Helper as multih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_csv_files(path):\n",
    "    pattern = r'^.*\\.csv$'\n",
    "    return [f for f in os.listdir(path) if bool(re.match(pattern,f))]\n",
    "    \n",
    "path = '../data/backlog/'\n",
    "csv_files = return_csv_files(path)\n",
    "df = pd.DataFrame()\n",
    "for csv in csv_files:\n",
    "    csv_df = pd.read_csv(path + csv)\n",
    "    df = pd.concat([df,csv_df])\n",
    "df['created'] = pd.to_datetime(df.created, unit = 's')\n",
    "df.index = range(0,len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Randomly shuffle the dataframe and generates a training, cross-validation, and test set\n",
    "'''\n",
    "random_df = df.reindex(np.random.permutation(df.index))\n",
    "training_df = random_df.iloc[0:12000]\n",
    "cross_validation_df = random_df.iloc[12000:15000]\n",
    "test_df = random_df.iloc[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cutoffs = [50, 150, 350]\n",
    "Y_training = training_df.score.apply(lambda d: multih.bucketize(cutoffs,d))\n",
    "Y_cross_validation = cross_validation_df.score.apply(lambda d: multih.bucketize(cutoffs,d))\n",
    "Y_test = test_df.score.apply(lambda d: multih.bucketize(cutoffs,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = (bayes.generate_words_and_scores(training_df.title, training_df.score)\n",
    "                 .groupby('word').agg({'score':['mean','std','median','count']}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words[('score','bucket')] = words[('score','median')].apply(lambda d: multih.bucketize(cutoffs,d))\n",
    "bucketize_words = words[words[('score','count')] > 20].sort_values(by=[('score','bucket'),('score','count')], ascending=False)\n",
    "top200ineachbucket = []\n",
    "for i in range(len(cutoffs) + 1):\n",
    "    if i == 2:\n",
    "        bucket = bucketize_words[bucketize_words[('score','bucket')] == i][:100]\n",
    "    else:\n",
    "        bucket = bucketize_words[bucketize_words[('score','bucket')] == i][:100]\n",
    "    top200ineachbucket.append(bucket)\n",
    "top200ineachbucket = pd.concat(top200ineachbucket).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 250\n",
    "top250 = words[words['score','count'] > 20].sort_values(by=('score','median'),ascending=False)[:n]\n",
    "bot250 = words[words['score','count'] > 20].sort_values(by=('score','median'),ascending=True)[:n]\n",
    "topbot500 = pd.concat([top250,bot250])\n",
    "topbot500_words = topbot500.index.values\n",
    "all_words = words.index.values\n",
    "word_vector_trained_upon= topbot500_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f500words = words[words['score','count'] > 20].sort_values(by=('score','count'),ascending=False)[:500].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bag_of_words(titles):\n",
    "    words = (bayes.generate_words_and_scores(training_df.title, training_df.score)\n",
    "                 .groupby('word').agg({'score':['mean','std','median','count']}))\n",
    "    words[('score','bucket')] = words[('score','median')].apply(lambda d: multih.bucketize(cutoffs,d))\n",
    "    bucketize_words = words[words[('score','count')] > 20].sort_values(by=[('score','bucket'),('score','count')], ascending=False)\n",
    "    top200ineachbucket = []\n",
    "    for i in range(len(cutoffs) + 1):\n",
    "        bucket = bucketize_words[bucketize_words[('score','bucket')] == i][:200]\n",
    "        top200ineachbucket.append(bucket)\n",
    "    top200ineachbucket = pd.concat(top200ineachbucket).index.values\n",
    "    return top200ineachbucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bayes_weights = [.9,.8,1.2,.6]\n",
    "bayes_weights = [1,1,1,1]\n",
    "def pxy_table(X_data, Y_data, words, num_i):\n",
    "    '''\n",
    "    Fix: Y_data must be a numpy array and X_data is a dataframe\n",
    "    p(word|y=i) = # of times y = i where word appears / # of time y = i\n",
    "    '''\n",
    "    Y_values = Y_data.values\n",
    "    pxyi = [{} for i in range(num_i)]\n",
    "    for index in range(len(words)):\n",
    "        for i in range(len(pxyi)):\n",
    "            word = words[index]\n",
    "            table = pxyi[i]\n",
    "            num = float(((X_data.iloc[:,index] == 1) & (Y_values == i)).sum() +1) \n",
    "            den = float((Y_values == i).sum() +2)\n",
    "            table[word] = num/den\n",
    "    return pxyi\n",
    "\n",
    "def py_table(Y_data, num_i):\n",
    "    py = []\n",
    "    for i in range(num_i):\n",
    "        py.append(float((Y_data == i).sum())/ len(Y_data))\n",
    "    return py\n",
    "\n",
    "def bayes_prob(x_hour, x_titles, pxy_table, py_table, pno):\n",
    "    titles_prob = []\n",
    "    for title_i in range(len(x_titles)):\n",
    "        title = x_titles[title_i]\n",
    "        title_prob = [1.0 for _ in range(len(py_table))]\n",
    "        for word in title:\n",
    "            for i in range((len(title_prob))):\n",
    "                if word in pxy_table[i]:\n",
    "                    title_prob[i] *= pxy_table[i][word]\n",
    "                #else:\n",
    "                #    title_prob[i] *= pno[i]\n",
    "        hour = X_hour.iloc[title_i]\n",
    "        title_prob = [(phour[i+hour*4]) * (bayes_weights[i]) * (title_prob[i]) for i in range(len(py_table))]\n",
    "        titles_prob.append(title_prob)\n",
    "    return titles_prob\n",
    "\n",
    "def pno_table(Y_data, num_i):\n",
    "    pno = []\n",
    "    for i in range(num_i):\n",
    "        pno.append(1 / float(sum(Y_data.values == i) +2))\n",
    "    return pno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.094"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note: This changes the word vector we train upon\n",
    "word_vector_trained_upon= top200ineachbucket\n",
    "\n",
    "\n",
    "X_training = bayes.generate_feature_vector((training_df.title), word_vector_trained_upon, bayes.common_words)\n",
    "X_training_df = pd.DataFrame(X_training)\n",
    "\n",
    "# number of training examples without any features mapped\n",
    "sum(X_training_df.sum(axis=1) == 0)/float(len(X_training_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pxy = pxy_table(X_training_df, Y_training, word_vector_trained_upon, len(cutoffs)+1)\n",
    "py = py_table(Y_training, len(cutoffs)+1)\n",
    "pno = pno_table(Y_training, len(cutoffs)+1)\n",
    "\n",
    "\n",
    "X_hour = training_df.created.apply(lambda d: d.hour).rename('hour')\n",
    "phour = ((pd.concat([X_hour,Y_training], axis=1).groupby(['hour','score']).size()\n",
    "          / pd.concat([X_hour,Y_training], axis=1).groupby(['hour']).size())).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_p_values(X_data, Y_data, bag_of_words, cutoffs):\n",
    "    \n",
    "    X_training = bayes.generate_feature_vector((X_data.title), bag_of_words, bayes.common_words)\n",
    "    X_training_df = pd.DataFrame(X_training)\n",
    "    \n",
    "    pxy = pxy_table(X_training_df, Y_data, bag_of_words, len(cutoffs)+1)\n",
    "    py = py_table(Y_data, len(cutoffs)+1)\n",
    "    pno = pno_table(Y_data, len(cutoffs)+1)\n",
    "    \n",
    "    X_hour = X_data.created.apply(lambda d: d.hour).rename('hour')\n",
    "    phour = ((pd.concat([X_hour,Y_data], axis=1).groupby(['hour','score']).size()\n",
    "              / pd.concat([X_hour,Y_data], axis=1).groupby(['hour']).size())).values\n",
    "    return pxy, py, pno, py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(predicted_Y, Y):\n",
    "    return sum(predicted_Y == Y)/float(len(predicted_Y))\n",
    "def accuracy_on_set(X_data, Y_data):\n",
    "    X_hour = training_df.created.apply(lambda d: d.hour).rename('hour')\n",
    "    phour = ((pd.concat([X_hour,Y_data], axis=1).groupby(['hour','score']).size()\n",
    "              / pd.concat([X_hour,Y_data], axis=1).groupby(['hour']).size())).values\n",
    "    probs_Y = pd.DataFrame(bayes_prob(phour, bayes.sanitize_and_split_titles(X_data.title),pxy,py,pno))\n",
    "    probs_Y.index = Y_data.index\n",
    "    prediction_Y = probs_Y.apply(lambda d: d.argmax(),axis=1)\n",
    "    prediction_Y.index = Y_data.index\n",
    "    return accuracy(prediction_Y, Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Model w/ Hour:\n",
      "\n",
      "training accuracy: 0.579333333333\n",
      "validation accuracy: 0.566666666667\n",
      "test accuracy: 0.562479173609\n"
     ]
    }
   ],
   "source": [
    "#Goal is 65% Accuracy\n",
    "\n",
    "print 'Bayesian Model w/ Hour:\\n'\n",
    "print 'training accuracy:', accuracy_on_set(training_df, Y_training)\n",
    "print 'validation accuracy:', accuracy_on_set(cross_validation_df, Y_cross_validation)\n",
    "print 'test accuracy:', accuracy_on_set(test_df, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs_Y = pd.DataFrame(bayes_prob(training_df, bayes.sanitize_and_split_titles(training_df.title),pxy,py,pno))\n",
    "probs_Y.index = Y_training.index\n",
    "prediction_Y = probs_Y.apply(lambda d: d.argmax(),axis=1)\n",
    "prediction_Y.index = Y_training.index\n",
    "\n",
    "debug_df = pd.concat([training_df.title,prediction_Y, Y_training], axis=1)\n",
    "debug_df.title = bayes.sanitize_and_split_titles(training_df.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Algorithm:\n",
    "p(y=i|title,hour,domain) = p(title|y=i,hour,domain)*p(y=i|hour,domain)/p(title|hour,domain)\n",
    "\n",
    "Assumptions:\n",
    "1. Distribution of words, given a score bucket are the same regardless of hour and domain. \n",
    "    This affects the conditional probabilities of words given the score bucket. In other words,\n",
    "    I assume that p(title|y=i,hour,domain) = p(title|y=i). \n",
    "    This assumption is made because there aren't enough training examples if we do segment \n",
    "    by hour as well as bucket and domain. I tried this and it led to overfitting on domains \n",
    "    leading to a high accuracy on the training set and low on the validation/test sets.\n",
    "\n",
    "Note: I get this warning, but this is intentional:\n",
    "        A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "        Try using .loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "    This is because I am trying to set a value on a slice and .loc does not allow me to do that\n",
    "'''\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "top_domains = ['selfnba', 'twitter','youtube','streamable','instagram','espn','imgur', 'other']\n",
    "top_domains = ['selfnba', 'twitter','youtube','streamable','other']\n",
    "\n",
    "def strip_domain(d):\n",
    "    for td in top_domains:\n",
    "        if td in d:\n",
    "            return td\n",
    "    return 'other'\n",
    "\n",
    "def bayes_prob_w_domain(x_titles, x_domain, x_hour, pxy_table, p_hour_domain, py, num_i):\n",
    "    titles_prob = []\n",
    "    for title_i in range(len(x_titles)):\n",
    "        title = x_titles[title_i]\n",
    "        domain = x_domain[title_i]\n",
    "        hour = x_hour[title_i]\n",
    "        title_prob = [1.0 for _ in range(num_i)]\n",
    "        for word in title:\n",
    "            for i in range((len(title_prob))):\n",
    "                if word in pxy_table[i]:\n",
    "                    title_prob[i] *= pxy_table[i][word]\n",
    "                #else:\n",
    "                #    title_prob[i] *= pno[i]\n",
    "        title_prob = [(p_hour_domain[(hour,domain,i)] if (hour,domain,i) in p_hour_domain else (py[i])) \n",
    "                      * (title_prob[i]) for i in range(num_i)]\n",
    "        titles_prob.append(title_prob)\n",
    "    return titles_prob\n",
    "\n",
    "def arg_max_list(d):\n",
    "    max_index = -1\n",
    "    max_val = 0\n",
    "    for i in range(len(d)):\n",
    "        if d[i] > max_val:\n",
    "            max_index = i\n",
    "            max_val = d[i]\n",
    "    return max_index\n",
    "\n",
    "def calculate_p(data_df, score_cutoffs, domains, word_vector):\n",
    "    df = data_df.copy()\n",
    "\n",
    "    df['score_bucket'] =  df.score.apply(lambda d: multih.bucketize(score_cutoffs,d))\n",
    "    df['domain'] = df.domain.apply(lambda d: strip_domain(''.join(d.split('.'))))\n",
    "    df['hour'] = df.created.apply(lambda d: d.hour).rename('hour')\n",
    "    df['title_list'] = bayes.sanitize_and_split_titles(df.title)\n",
    "    num_i = len(cutoffs) + 1\n",
    "    \n",
    "    X_training = bayes.generate_feature_vector((df.title), word_vector, bayes.common_words)\n",
    "    X_training_df = pd.DataFrame(X_training)\n",
    "    Y_data = df.score_bucket\n",
    "    pxy = pxy_table(X_training_df, Y_data, word_vector, len(score_cutoffs)+1)\n",
    "    \n",
    "    #prob y parameterized by hour and domain\n",
    "    phd_num = (df[['hour','domain','score_bucket']].groupby(['hour','domain','score_bucket']).size()).astype(float)\n",
    "    phd_den = df[['hour','domain','score_bucket']].groupby(['hour','domain']).size()\n",
    "    \n",
    "    for i in phd_den.index:\n",
    "        phd_num[i] = (phd_num[i]/phd_den[i])\n",
    "    phourdomain = phd_num\n",
    "    py = py_table(df.score_bucket, num_i)\n",
    "    return pxy, phourdomain, py\n",
    "\n",
    "\n",
    "# Calculates P_Values\n",
    "pxy_nb, phd_nb, py_nb = calculate_p(training_df\n",
    "                                    , cutoffs\n",
    "                                    , top_domains\n",
    "                                    , word_vector_trained_upon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Model w/ Domain and Hour\n",
      "\n",
      "training accuracy: 0.603166666667\n",
      "validation accuracy: 0.590333333333\n",
      "test accuracy: 0.581806064645\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy_hd(data_df, pxy, phd, py, score_cutoffs):\n",
    "    num_i = len(score_cutoffs) +1\n",
    "    df = data_df.copy()\n",
    "    df['score_bucket'] =  df.score.apply(lambda d: multih.bucketize(score_cutoffs,d))\n",
    "    df['domain'] = df.domain.apply(lambda d: strip_domain(''.join(d.split('.'))))\n",
    "    df['hour'] = df.created.apply(lambda d: d.hour).rename('hour')\n",
    "    df['title_list'] = bayes.sanitize_and_split_titles(df.title)\n",
    "    \n",
    "    df['Y_probs'] = bayes_prob_w_domain(df.title_list.values \n",
    "                                        ,df.domain.values\n",
    "                                        ,df.hour.values\n",
    "                                        ,pxy\n",
    "                                        ,phd\n",
    "                                        ,py\n",
    "                                        ,num_i)\n",
    "\n",
    "\n",
    "    df['Y_predicted'] = df.Y_probs.apply(lambda d: arg_max_list(d)) \n",
    "    return sum(df['Y_predicted'] == df['score_bucket'])/ float(len(df))#,sum((df['Y_predicted'] - df['score_bucket']).abs() <= 1)/ float(len(df))\n",
    "\n",
    "print 'Bayesian Model w/ Domain and Hour\\n'\n",
    "print 'training accuracy:', get_accuracy_hd(training_df, pxy_nb, phd_nb, py_nb, cutoffs)\n",
    "print 'validation accuracy:', get_accuracy_hd(cross_validation_df, pxy_nb, phd_nb, py_nb, cutoffs)\n",
    "print 'test accuracy:', get_accuracy_hd(test_df, pxy_nb, phd_nb, py_nb, cutoffs)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
