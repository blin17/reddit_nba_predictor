{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Analysis of /r/nba Posts\n",
    "@author: Brian Lin\n",
    "'''\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import Bayes_Helper as bayes\n",
    "import Multinomial_Helper as multih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_csv_files(path):\n",
    "    pattern = r'^.*\\.csv$'\n",
    "    return [f for f in os.listdir(path) if bool(re.match(pattern,f))]\n",
    "    \n",
    "path = 'data/backlog/'\n",
    "csv_files = return_csv_files(path)\n",
    "df = pd.DataFrame()\n",
    "for csv in csv_files:\n",
    "    csv_df = pd.read_csv(path + csv)\n",
    "    df = pd.concat([df,csv_df])\n",
    "df['created'] = pd.to_datetime(df.created, unit = 's')\n",
    "df.index = range(0,len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Randomly shuffle the dataframe and generates a training, cross-validation, and test set\n",
    "'''\n",
    "random_df = df.reindex(np.random.permutation(df.index))\n",
    "training_df = random_df.iloc[0:12000]\n",
    "cross_validation_df = random_df.iloc[12000:15000]\n",
    "test_df = random_df.iloc[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cutoffs = [50, 150, 350]\n",
    "Y_training = training_df.score.apply(lambda d: multih.bucketize(cutoffs,d))\n",
    "Y_cross_validation = cross_validation_df.score.apply(lambda d: multih.bucketize(cutoffs,d))\n",
    "Y_test = test_df.score.apply(lambda d: multih.bucketize(cutoffs,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = (bayes.generate_words_and_scores(training_df.title, training_df.score)\n",
    "                 .groupby('word').agg({'score':['mean','std','median','count']}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words[('score','bucket')] = words[('score','median')].apply(lambda d: multih.bucketize(cutoffs,d))\n",
    "bucketize_words = words[words[('score','count')] > 20].sort_values(by=[('score','bucket'),('score','count')], ascending=False)\n",
    "top200ineachbucket = []\n",
    "for i in range(len(cutoffs) + 1):\n",
    "    if i == 2:\n",
    "        bucket = bucketize_words[bucketize_words[('score','bucket')] == i][:400]\n",
    "    else:\n",
    "        bucket = bucketize_words[bucketize_words[('score','bucket')] == i][:200]\n",
    "    top200ineachbucket.append(bucket)\n",
    "top200ineachbucket = pd.concat(top200ineachbucket).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 250\n",
    "top250 = words[words['score','count'] > 20].sort_values(by=('score','median'),ascending=False)[:n]\n",
    "bot250 = words[words['score','count'] > 20].sort_values(by=('score','median'),ascending=True)[:n]\n",
    "topbot500 = pd.concat([top250,bot250])\n",
    "topbot500_words = topbot500.index.values\n",
    "all_words = words.index.values\n",
    "word_vector_trained_upon= topbot500_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f500words = words[words['score','count'] > 20].sort_values(by=('score','count'),ascending=False)[:500].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.041083333333333333"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note: This changes the word vector we train upon\n",
    "word_vector_trained_upon= top200ineachbucket\n",
    "\n",
    "\n",
    "X_training = bayes.generate_feature_vector((training_df.title), word_vector_trained_upon, bayes.common_words)\n",
    "X_training_df = pd.DataFrame(X_training)\n",
    "\n",
    "# number of training examples without any features mapped\n",
    "sum(X_training_df.sum(axis=1) == 0)/float(len(X_training_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bayes_weights = [.9,.8,1.2,.6]\n",
    "#bayes_weights = [1,1,1,1]\n",
    "def pxy_table(X_data, Y_data, words, num_i):\n",
    "    '''\n",
    "    p(word|y=i) = # of times y = i where word appears / # of time y = i\n",
    "    '''\n",
    "    pxyi = [{} for i in range(num_i)]\n",
    "    for index in range(len(words)):\n",
    "        for i in range(len(pxyi)):\n",
    "            word = words[index]\n",
    "            table = pxyi[i]\n",
    "            num = float(((X_data.iloc[:,index] == 1) & (Y_data == i)).sum() +1) \n",
    "            den = float((Y_data == i).sum() +2)\n",
    "            table[word] = num/den\n",
    "    return pxyi\n",
    "\n",
    "def py_table(Y_data, num_i):\n",
    "    py = []\n",
    "    for i in range(num_i):\n",
    "        py.append(float((Y_data == i).sum())/ len(Y_data))\n",
    "    return py\n",
    "\n",
    "def bayes_prob(training_df, x_titles, pxy_table, py_table, pno):\n",
    "    titles_prob = []\n",
    "    X_hour = training_df.created.apply(lambda d: d.hour).rename('hour')\n",
    "    for title_i in range(len(x_titles)):\n",
    "        title = x_titles[title_i]\n",
    "        title_prob = [1.0 for _ in range(len(py_table))]\n",
    "        for word in title:\n",
    "            for i in range((len(title_prob))):\n",
    "                if word in pxy_table[i]:\n",
    "                    title_prob[i] *= pxy_table[i][word]\n",
    "                #else:\n",
    "                #    title_prob[i] *= pno[i]\n",
    "        hour = X_hour.iloc[title_i]\n",
    "        if title_i % 1000 == 0:\n",
    "            print title, hour, py\n",
    "        title_prob = [(phour[len(py_table)*4 + hour]) * (bayes_weights[i]) * (title_prob[i]) for i in range(len(py_table))]\n",
    "        titles_prob.append(title_prob)\n",
    "    return titles_prob\n",
    "\n",
    "def pno_table(Y_data, num_i):\n",
    "    pno = []\n",
    "    for i in range(num_i):\n",
    "        pno.append(1 / float(sum(Y_data.values == i) +2))\n",
    "    return pno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pxy = pxy_table(X_training_df, Y_training.values, word_vector_trained_upon, len(cutoffs)+1)\n",
    "py = py_table(Y_training, len(cutoffs)+1)\n",
    "pno = pno_table(Y_training, len(cutoffs)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.55418381,  0.16186557,  0.1138546 ,  0.17009602,  0.59051186,\n",
       "        0.13732834,  0.12484395,  0.14731586,  0.59826947,  0.13844252,\n",
       "        0.11619283,  0.14709518,  0.60516605,  0.14760148,  0.11193112,\n",
       "        0.13530135,  0.62764457,  0.14245416,  0.08744711,  0.14245416,\n",
       "        0.61103048,  0.14949202,  0.1030479 ,  0.13642961,  0.64285714,\n",
       "        0.14603175,  0.09206349,  0.11904762,  0.64123377,  0.12662338,\n",
       "        0.0974026 ,  0.13474026,  0.61066236,  0.15831987,  0.08562197,\n",
       "        0.1453958 ,  0.59369527,  0.1821366 ,  0.09281961,  0.13134851,\n",
       "        0.63093415,  0.143951  ,  0.08269525,  0.1424196 ,  0.61740558,\n",
       "        0.136289  ,  0.08702791,  0.1592775 ,  0.65257353,  0.15257353,\n",
       "        0.08272059,  0.11213235,  0.72010178,  0.10687023,  0.07379135,\n",
       "        0.09923664,  0.74222222,  0.14666667,  0.04444444,  0.06666667,\n",
       "        0.7804878 ,  0.06707317,  0.06707317,  0.08536585,  0.75510204,\n",
       "        0.10884354,  0.04081633,  0.0952381 ,  0.78512397,  0.0661157 ,\n",
       "        0.08264463,  0.0661157 ,  0.648     ,  0.112     ,  0.112     ,\n",
       "        0.128     ,  0.55681818,  0.13068182,  0.125     ,  0.1875    ,\n",
       "        0.52868852,  0.11065574,  0.15163934,  0.20901639,  0.54427083,\n",
       "        0.1484375 ,  0.11458333,  0.19270833,  0.54166667,  0.16666667,\n",
       "        0.10869565,  0.18297101,  0.54062038,  0.14918759,  0.11225997,\n",
       "        0.19793205])"
      ]
     },
     "execution_count": 983,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hour = training_df.created.apply(lambda d: d.hour).rename('hour')\n",
    "phour = (pd.concat([hour,Y_training], axis=1).groupby(['hour','score']).size()/ pd.concat([hour,Y_training], axis=1).groupby(['hour']).size())\n",
    "#phour.groupby(['score']).mean()\n",
    "#p_time(training_df)\n",
    "#phour[(phour.hour==0) & (phour.score ==0)][0].values\n",
    "phour.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 974,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hour.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(predicted_Y, Y):\n",
    "    return sum(predicted_Y == Y)/float(len(predicted_Y))\n",
    "def accuracy_on_set(X_data, Y_data):\n",
    "    probs_Y = pd.DataFrame(bayes_prob(X_data, bayes.sanitize_and_split_titles(X_data.title),pxy,py,pno))\n",
    "    probs_Y.index = Y_data.index\n",
    "    prediction_Y = probs_Y.apply(lambda d: d.argmax(),axis=1)\n",
    "    prediction_Y.index = Y_data.index\n",
    "    return accuracy(prediction_Y, Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: ['pre-draft', 'thread', 'r/nba', 'draft', 'round', 'results', 'round', 'starts', 'pm', 'est'] 22 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['michael', 'jordan', 'brixton', 'london', 'uk', 'mid', \"80's\"] 7 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "[\"you're\", 'westbrook', \"isn't\", 'best', 'interest', 'commit', 'team', 'via', 'trade', 'competitive', 'reasons'] 8 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['top', 'centers', 'currently', 'playing'] 9 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['kobe', 'bryant', '@usabasketball', 'deep', 'strong'] 7 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['gardner', 'league', 'source', 'indicates', 'bucks', 'made', 'qualifying', 'offer', 'center', 'miles', 'plumlee', 'making', 'restricted', 'free', 'agent'] 10 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['tom', 'thibodeau', 'team', 'usa', 'off', 'wolves', 'more'] 3 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['khris', 'middleton', 'past', 'season', 'increased', 'scoring', 'average', 'enough', 'career', 'scoring', 'average', 'higher', 'every', 'individual', 'season', 'besides', 'past'] 3 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['vertical', 'pod', 'jj', 'redick', 'ben', 'winston'] 3 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['looking', '+/-', 'last', 'night', 'shows', 'productive', 'warriors', 'bench', 'game', 'finals'] 4 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['ballad', 'banana', 'boat', 'brotherhood', 'celebrating', 'friendship', 'lebron', 'd-wade', 'melo', 'cp3', 'five', 'scenes', 'told', 'four', 'themselves'] 0 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['cavs', 'exploit', 'shaun', 'livingston', 'letting', 'shoot', '3s', 'career', '19%', 'shooter', '0.1', '3pa'] 10 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "0.580416666667\n",
      "validation accuracy: ['angry', 'd', 'wade', 'scores', '24', 'points', '4th', 'qtr', '2009', 'vs', 'knicks][46', 'pts', '10', 'ast', 'reb', 'stls', 'blocks'] 4 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['york', 'knicks', 'discussions', 'trading', 'derrick', 'rose'] 3 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['r/nba', 'whose', 'line', 'anyway', 'offseason', 'edition'] 0 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "0.516\n",
      "test accuracy: ['second', 'best', 'player', 'east'] 5 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['team', 'usa', 'back-outs', 'vs'] 13 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['bobby', 'marks', 'twitter', 'clippers', '$2.5m', 'below', 'tax', '$6.5m', 'below', 'hard', 'cap', 'la', 'still', 'available', '$2.2m', 'bi-annual', 'exception'] 6 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['timberwolves', '5th', 'best', 'team', 'nba', 'straight', 'kat', 'himself'] 8 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "0.538820393202\n"
     ]
    }
   ],
   "source": [
    "#Goal is 65% Accuracy\n",
    "\n",
    "print 'training accuracy:', accuracy_on_set(training_df, Y_training)\n",
    "print 'validation accuracy:', accuracy_on_set(cross_validation_df, Y_cross_validation)\n",
    "print 'test accuracy:', accuracy_on_set(test_df, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pre-draft', 'thread', 'r/nba', 'draft', 'round', 'results', 'round', 'starts', 'pm', 'est'] 22 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['michael', 'jordan', 'brixton', 'london', 'uk', 'mid', \"80's\"] 7 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "[\"you're\", 'westbrook', \"isn't\", 'best', 'interest', 'commit', 'team', 'via', 'trade', 'competitive', 'reasons'] 8 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['top', 'centers', 'currently', 'playing'] 9 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['kobe', 'bryant', '@usabasketball', 'deep', 'strong'] 7 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['gardner', 'league', 'source', 'indicates', 'bucks', 'made', 'qualifying', 'offer', 'center', 'miles', 'plumlee', 'making', 'restricted', 'free', 'agent'] 10 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['tom', 'thibodeau', 'team', 'usa', 'off', 'wolves', 'more'] 3 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['khris', 'middleton', 'past', 'season', 'increased', 'scoring', 'average', 'enough', 'career', 'scoring', 'average', 'higher', 'every', 'individual', 'season', 'besides', 'past'] 3 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n",
      "['vertical', 'pod', 'jj', 'redick', 'ben', 'winston'] 3 [0.6120833333333333, 0.14333333333333334, 0.09966666666666667, 0.14491666666666667]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-977-dba831078e8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprobs_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbayes_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msanitize_and_split_titles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpxy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprobs_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprediction_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprediction_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-971-d16876404021>\u001b[0m in \u001b[0;36mbayes_prob\u001b[0;34m(training_df, x_titles, pxy_table, py_table, pno)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtitle_i\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtitle_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphour\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mphour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbayes_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtitle_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mtitles_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtitles_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brianlin/anaconda/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    824\u001b[0m                       else fill_bool)\n\u001b[1;32m    825\u001b[0m             return filler(self._constructor(na_op(self.values, other.values),\n\u001b[0;32m--> 826\u001b[0;31m                                             index=self.index, name=name))\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brianlin/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "probs_Y = pd.DataFrame(bayes_prob(training_df, bayes.sanitize_and_split_titles(training_df.title),pxy,py,pno))\n",
    "probs_Y.index = Y_training.index\n",
    "prediction_Y = probs_Y.apply(lambda d: d.argmax(),axis=1)\n",
    "prediction_Y.index = Y_training.index\n",
    "\n",
    "debug_df = pd.concat([training_df.title,prediction_Y, Y_training], axis=1)\n",
    "debug_df.title = bayes.sanitize_and_split_titles(training_df.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_Y[Y_training != prediction_Y].value_counts()/prediction_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_training[Y_training != prediction_Y].value_counts()/Y_training.value_counts()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
